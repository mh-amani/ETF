{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import bootstrap\n",
    "from collections import Counter, defaultdict\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import ast\n",
    "project_root_dir = \"../\"\n",
    "\n",
    "import os\n",
    "work_dir = os.path.abspath(project_root_dir)\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_root_dir)\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger('wandb').setLevel(logging.WARNING)\n",
    "logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "from src.utils import get_linearization_class\n",
    "from src.datamodules import IEGenericOutputDataset\n",
    "from src.metrics import TSF1, TSPrecision, TSRecall\n",
    "import src.utils.evaluation_helpers as evaluation_helpers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "\n",
    "lc = get_linearization_class(\"fully_expanded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dataframe td {\n",
       "    white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".dataframe td {\n",
    "    white-space: nowrap;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ Prameters to set ~~~\n",
    "\n",
    "ORDERED_METRICS = ['P', 'R', 'F1']\n",
    "\n",
    "bootstrap_n = 150\n",
    "# target_col_prediction_col_pairs = [(\"gt_majority\", \"lin_triplet_set_rebel\"), (\"gt_majority\", \"lin_triplet_set_synthie\"), (\"gt_any\", \"lin_triplet_set_rebel\"), (\"gt_any\", \"lin_triplet_set_synthie\")]\n",
    "target_col_prediction_col_pairs = [(\"gt_majority\", \"lin_triplet_set_rebel\"), (\"gt_majority\", \"lin_triplet_set_synthie\"), (\"gt_majority\", \"lin_triplet_set_synthie_base\"), (\"gt_majority\", \"lin_triplet_set_genie_base\")]\n",
    "# target_col_prediction_col_pairs = [(\"gt_majority\", \"lin_triplet_set_synthie_base\"), (\"gt_majority\", \"lin_triplet_set_genie_base\")]\n",
    "\n",
    "model_name2col = {\n",
    "    \"GenIE{\\\\footnotesize~{T5-base}}\": \"lin_triplet_set_genie_base\", \n",
    "    \"SynthIE{\\\\footnotesize~{T5-base}}\": \"lin_triplet_set_synthie_base\", \n",
    "    \"SynthIE{\\\\footnotesize~{T5-large}}\": \"lin_triplet_set_synthie\", \n",
    "    \"REBEL{\\\\footnotesize~{Gold}}\":\"lin_triplet_set_rebel\"\n",
    "}\n",
    "\n",
    "ground_truth_cols_to_present = [\"gt_majority\"]\n",
    "discard_datapoints_with_no_triplets_in_gt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df, suffix=\"\"):\n",
    "    gt_majoritys = []\n",
    "    first_workers = []\n",
    "    second_workers = []\n",
    "    third_workers = []\n",
    "    gt_any_worker = []\n",
    "\n",
    "    for triplet_set, gt_majority, first_worker, second_worker, third_worker in zip(df[f\"lin_triplet_set{suffix}\"], df[f\"gt_majority{suffix}\"], df[f\"first_worker{suffix}\"], df[f\"second_worker{suffix}\"], df[f\"third_worker{suffix}\"]):\n",
    "        triplets = lc.text_to_triplet_list(triplet_set, return_set=False)\n",
    "        gt_majority = [triplets[int(idx)] for idx in sorted(ast.literal_eval(gt_majority))]\n",
    "\n",
    "        any_worker = [triplets[int(idx)] for idx in sorted(ast.literal_eval(first_worker) + ast.literal_eval(second_worker) + ast.literal_eval(third_worker))]\n",
    "\n",
    "        first_worker = [triplets[int(idx)] for idx in sorted(ast.literal_eval(first_worker))]\n",
    "        second_worker = [triplets[int(idx)] for idx in sorted(ast.literal_eval(second_worker))]\n",
    "        third_worker = [triplets[int(idx)] for idx in sorted(ast.literal_eval(third_worker))]\n",
    "\n",
    "        gt_majoritys.append(lc.triplet_list_to_text(gt_majority)[0])\n",
    "        first_workers.append(lc.triplet_list_to_text(first_worker)[0])\n",
    "        second_workers.append(lc.triplet_list_to_text(second_worker)[0])\n",
    "        third_workers.append(lc.triplet_list_to_text(third_worker)[0])\n",
    "        gt_any_worker.append(lc.triplet_list_to_text(any_worker)[0])\n",
    "\n",
    "    df[f\"gt_majority{suffix}\"] = gt_majoritys\n",
    "    df[f\"gt_any{suffix}\"] = gt_any_worker\n",
    "    df[f\"first_worker{suffix}\"] = first_workers\n",
    "    df[f\"second_worker{suffix}\"] = second_workers\n",
    "    df[f\"third_worker{suffix}\"] = third_workers\n",
    "\n",
    "def processed_merged_df(df, suffixes):\n",
    "    for suffix in suffixes:\n",
    "        process_df(df, suffix=suffix)\n",
    "\n",
    "    gt_majorities = []\n",
    "    gt_anys = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        gt_majority_rebel = row[\"gt_majority_rebel\"]\n",
    "        gt_majority_synthie = row[\"gt_majority_synthie\"]\n",
    "        \n",
    "        gt_majority = set(list(lc.text_to_triplet_list(gt_majority_rebel, verbose=False)) + list(lc.text_to_triplet_list(gt_majority_synthie, verbose=False)))\n",
    "        gt_majorities.append(lc.triplet_list_to_text(gt_majority)[0])\n",
    "\n",
    "        gt_any_rebel = row[\"gt_any_rebel\"]\n",
    "        gt_any_synthie = row[\"gt_any_synthie\"]\n",
    "\n",
    "        gt_any = set(list(lc.text_to_triplet_list(gt_any_rebel, verbose=False)) + list(lc.text_to_triplet_list(gt_any_synthie, verbose=False)))\n",
    "        gt_anys.append(lc.triplet_list_to_text(sorted(gt_any))[0])\n",
    "\n",
    "\n",
    "    df[\"gt_majority\"] = gt_majorities\n",
    "    df[\"gt_any\"] = gt_anys\n",
    "\n",
    "def filter_df(df, ids_to_keep=None, ids_to_drop=None):\n",
    "    assert ids_to_keep is not None or ids_to_drop is not None and not (ids_to_keep is not None and ids_to_drop is not None)\n",
    "\n",
    "    if ids_to_keep is not None:\n",
    "        return df[df.id.isin(ids_to_keep)].reset_index(drop=True)\n",
    "    \n",
    "    if ids_to_drop is not None:\n",
    "        return df[~df.id.isin(ids_to_drop)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = [\"_rebel\", \"_synthie\"]\n",
    "\n",
    "def get_gt_majority_cols(suffixes=suffixes):\n",
    "    gt_majority_cols = [\"id\", \"input\", 'gt_majority']\n",
    "    for suffix in suffixes:\n",
    "        gt_majority_cols.append(f\"gt_majority{suffix}\")\n",
    "    return gt_majority_cols\n",
    "\n",
    "def get_all_annotations(suffixes, show_majority, show_majority_per_suffix):\n",
    "    all_annotations = [\"first_worker\", \"second_worker\", \"third_worker\"]\n",
    "    \n",
    "    if show_majority:\n",
    "        cols = [\"id\", \"input\", 'gt_majority']\n",
    "    else:\n",
    "        cols = [\"id\", \"input\"]\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        if show_majority_per_suffix:\n",
    "            cols.append(f\"gt_majority{suffix}\")\n",
    "        \n",
    "        for col in all_annotations:\n",
    "            cols.append(f\"{col}{suffix}\")\n",
    "\n",
    "    return cols\n",
    "\n",
    "def wrap_df_text_results(df, cols_to_show=['input', 'lin_triplet_set_rebel', 'lin_triplet_set_synthie'], input_max_col=70):\n",
    "    tdf = df.copy()\n",
    "    tdf = tdf[cols_to_show]\n",
    "    tdf['input'] = tdf['input'].str.wrap(input_max_col)\n",
    "        \n",
    "    for col in tdf.columns:\n",
    "        if col == \"id\":\n",
    "            continue\n",
    "        if type(tdf[col][0]) == str:\n",
    "            tdf[col] = tdf[col].str.replace(\"\\[e\\]|\\[et\\]\", \"[e]\\\\n\", regex=True)\n",
    "        else:\n",
    "            tdf[col] = tdf[col].apply(lambda x: \"\\\\n\".join([re.sub(\"\\[e\\]|\\[et\\]\", \"[e]\\\\n\", p) for p in x]))\n",
    "\n",
    "    display(HTML(tdf.to_html().replace(\"\\\\n\",\"<br>\")))\n",
    "\n",
    "def show_df(df, cols_to_show=['input', 'lin_triplet_set_rebel', 'lin_triplet_set_synthie'], input_max_col=70):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, \"display.expand_frame_repr\", False, 'display.max_colwidth', None, 'display.width', None): \n",
    "        wrap_df_text_results(df, cols_to_show, input_max_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_dataset(df, target_col, prediction_col):\n",
    "    ids = df[\"id\"].to_list()\n",
    "    lin_targets = df[target_col].to_list()\n",
    "    lin_preds = df[prediction_col].to_list()\n",
    "\n",
    "    # get a list of id, target, prediction dicts per datapoint\n",
    "    data = []\n",
    "    for id, lin_target, lin_pred in zip(ids, lin_targets, lin_preds):\n",
    "        data.append({\n",
    "            \"id\": id,\n",
    "            \"target\": lin_target,\n",
    "            \"prediction\": lin_pred\n",
    "        })\n",
    "\n",
    "    output_dataset = IEGenericOutputDataset(data=data, linearization_class_id=\"fully_expanded\", seed=123)\n",
    "    return output_dataset\n",
    "\n",
    "def get_df_from_wandb_run(wandb_run_path, ids_to_keep, suffix):\n",
    "    wandb_run_config, wandb_run_hydra_config, abs_exp_dir = evaluation_helpers.prepare_data_for_experiment(wandb_run_path, work_dir=project_root_dir, log_func=print)\n",
    "    print(\"Loading the output dataset corresponding to run:\", wandb_run_hydra_config['run_name'])\n",
    "    linearization_class_id = wandb_run_hydra_config[\"datamodule\"].get(\"linearization_class_id\")\n",
    "\n",
    "    output_dataset_parameters = {\"data_dir\": os.path.join(abs_exp_dir, \"predictions\"), \"linearization_class_id\": linearization_class_id, \"seed\": 123}\n",
    "    output_dataset = IEGenericOutputDataset(**output_dataset_parameters)\n",
    "    data = [dp for dp in output_dataset.data if dp['id'] in ids_to_keep]\n",
    "\n",
    "    ids = [dp['id'] for dp in data]\n",
    "    input = [dp['input'] for dp in data]\n",
    "    target = [dp['target'] for dp in data]\n",
    "    lin_triplet_set = [dp['prediction'][0] for dp in data]\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(ids, input, target, lin_triplet_set)), columns =['id', 'input', 'lin_triplet_set_rebel', f'lin_triplet_set{suffix}'])\n",
    "    return df\n",
    "\n",
    "\n",
    "get_metric_name_from_metric = lambda metric, macro: metric.name + \"_macro\" if macro else metric.name \n",
    "get_metric_name = lambda metric_name, macro: metric_name + \"_macro\" if macro else metric_name\n",
    "\n",
    "def compute_metric(metric_name, output_dataset, seed=None, macro=False):\n",
    "    assert metric_name in [TSPrecision.name, TSRecall.name, TSF1.name]\n",
    "    \n",
    "    if metric_name == TSPrecision.name:\n",
    "        metric = TSPrecision()\n",
    "    elif metric_name == TSRecall.name:\n",
    "        metric = TSRecall()\n",
    "    elif metric_name == TSF1.name:\n",
    "        metric = TSF1()\n",
    "\n",
    "    if seed is None:\n",
    "        macro_metadata_dict = None\n",
    "\n",
    "        if macro:\n",
    "            macro_metadata_dict = evaluation_helpers.get_macro_metrics_computation_metadata(\n",
    "                output_dataset, consider_prediction_triplets=True\n",
    "            )\n",
    "\n",
    "        return metric.compute_from_dataset(output_dataset, bucket_metadata_dict=macro_metadata_dict)[1]\n",
    "    \n",
    "    original_data = output_dataset.data\n",
    "    output_dataset.data = output_dataset.get_bootstrapped_data(seed=seed)\n",
    "\n",
    "    macro_metadata_dict = None\n",
    "    if macro:\n",
    "        macro_metadata_dict = evaluation_helpers.get_macro_metrics_computation_metadata(\n",
    "            output_dataset, consider_prediction_triplets=True\n",
    "        )   \n",
    "    score = metric.compute_from_dataset(output_dataset, bucket_metadata_dict=macro_metadata_dict)[1]\n",
    "    \n",
    "    output_dataset.data = original_data\n",
    "    \n",
    "    return score\n",
    "\n",
    "def compute_metrics(output_dataset, macro=False, scores={}, bootstrap_n=None, metric_names = [TSPrecision.name, TSRecall.name, TSF1.name]):\n",
    "    if bootstrap_n is None:\n",
    "        for metric_name in metric_names:\n",
    "            scores[get_metric_name(metric_name, macro)] = compute_metric(metric_name, output_dataset, macro=macro)\n",
    "        return scores\n",
    "\n",
    "    for metric_name in metric_names:\n",
    "        seed = 100\n",
    "        bootstrap_scores = []\n",
    "\n",
    "        for i in range(bootstrap_n):\n",
    "            s = compute_metric(metric_name, output_dataset=output_dataset, seed=seed, macro=macro)\n",
    "            bootstrap_scores.append(s)\n",
    "            seed += 1\n",
    "        \n",
    "        scores[get_metric_name(metric_name, macro)] = evaluation_helpers.get_std_based_ci(bootstrap_scores)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massaging the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"human_eval_data/mturk_task2_results.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "# get a single row per datapoint\n",
    "df_rebel_data = df[df.dataset == \"rebel\"]\n",
    "df_rebel_data = df_rebel_data.drop(columns=[\"dataset\"])\n",
    "df_rebel_data = df_rebel_data.drop(columns=[\"triplets_formatted\"])\n",
    "df_rebel_data.columns = [\"id\", \"lin_triplet_set\", \"input\", \"gt_majority\", \"num_workers\", \"first_worker\", \"second_worker\", \"third_worker\"]\n",
    "\n",
    "df_synthie_data = df[df.dataset == \"model\"]\n",
    "df_synthie_data = df_synthie_data.drop(columns=[\"dataset\"])\n",
    "df_synthie_data = df_synthie_data.drop(columns=[\"triplets_formatted\"])\n",
    "df_synthie_data.columns = [\"id\", \"lin_triplet_set\", \"input\", \"gt_majority\", \"num_workers\", \"first_worker\", \"second_worker\", \"third_worker\"]\n",
    "\n",
    "df_merged = pd.merge(df_rebel_data, df_synthie_data, on=[\"id\", \"input\", \"num_workers\"], how=\"inner\", suffixes=(\"_rebel\", \"_synthie\"))\n",
    "df_merged['input'] = df_merged['input'].apply(lambda x: x.replace('\\\\\"', '\"')).apply(lambda x: x.replace(\"\\\\'\", \"'\")) # unescape quotes\n",
    "processed_merged_df(df_merged, [\"_rebel\", \"_synthie\"])\n",
    "if discard_datapoints_with_no_triplets_in_gt:\n",
    "    df_merged = df_merged[df_merged['gt_majority'] != u\"\"].reset_index(drop=True)\n",
    "datapoint_ids = set(df_merged.id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory already exists: ../logs/inference/runs/inf_full_fe_rebel_ms_base_medium_lr_datamodule-rebel_world-genie_t5_tokenizeable_split-test_constraint-R-max-T5_lp-0.8/2023-02-02_05-56-12\n",
      "Loading the existing results\n",
      "Loading the output dataset corresponding to run: inf_full_fe_rebel_ms_base_medium_lr_datamodule-rebel_world-genie_t5_tokenizeable_split-test_constraint-R-max-T5_lp-0.8\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Loaded the predictions for 114953 datapoints from ../logs/inference/runs/inf_full_fe_rebel_ms_base_medium_lr_datamodule-rebel_world-genie_t5_tokenizeable_split-test_constraint-R-max-T5_lp-0.8/2023-02-02_05-56-12/predictions\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Dataset statistics: {'num_datapoints': 114953, 'num_triplets': {'P': 251898, 'T': 257129}, 'num_unique_entities': {'P': 137455, 'T': 151997}, 'num_unique_relations': {'P': 389, 'T': 580}}\n"
     ]
    }
   ],
   "source": [
    "# include GenIE base data\n",
    "genie_base_wandb_run_path = 'epfl-dlab/SynthIE/2h4ibqlg'\n",
    "genie_base_suffix = \"_genie_base\"\n",
    "\n",
    "genie_base_df = get_df_from_wandb_run(genie_base_wandb_run_path, datapoint_ids, genie_base_suffix)\n",
    "df_merged = pd.merge(df_merged, genie_base_df, on=[\"id\", \"input\", \"lin_triplet_set_rebel\"], how=\"inner\", suffixes=(\"\", \"\"))\n",
    "assert len(df_merged) == len(datapoint_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory already exists: ../logs/inference/runs/inf_full_fe_fully_synthetic_ms_base_medium_lr_datamodule-rebel_world-genie_t5_tokenizeable_split-test_constraint-R-max-T5_lp-0.8/2023-02-02_22-09-02\n",
      "Loading the existing results\n",
      "Loading the output dataset corresponding to run: inf_full_fe_fully_synthetic_ms_base_medium_lr_datamodule-rebel_world-genie_t5_tokenizeable_split-test_constraint-R-max-T5_lp-0.8\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Loaded the predictions for 114953 datapoints from ../logs/inference/runs/inf_full_fe_fully_synthetic_ms_base_medium_lr_datamodule-rebel_world-genie_t5_tokenizeable_split-test_constraint-R-max-T5_lp-0.8/2023-02-02_22-09-02/predictions\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Dataset statistics: {'num_datapoints': 114953, 'num_triplets': {'P': 375052, 'T': 257129}, 'num_unique_entities': {'P': 158537, 'T': 151997}, 'num_unique_relations': {'P': 836, 'T': 580}}\n"
     ]
    }
   ],
   "source": [
    "# include SynthIE-base data\n",
    "synthie_base_wandb_run_path = 'epfl-dlab/SynthIE/2mlj6x38'\n",
    "synthie_base_suffix = \"_synthie_base\"\n",
    "\n",
    "synthie_base_df = get_df_from_wandb_run(synthie_base_wandb_run_path, datapoint_ids, synthie_base_suffix)\n",
    "df_merged = df_merged.merge(synthie_base_df, on=[\"id\", \"input\", \"lin_triplet_set_rebel\"], how=\"inner\", suffixes=(\"\", \"\"))\n",
    "assert len(df_merged) == len(datapoint_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:src.datamodules.ie_generic:[Output DS] Got 49 datapoints from the `data` passed to the constructor\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Dataset statistics: {'num_datapoints': 49, 'num_triplets': {'P': 125, 'T': 150}, 'num_unique_entities': {'P': 147, 'T': 169}, 'num_unique_relations': {'P': 39, 'T': 55}}\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Got 49 datapoints from the `data` passed to the constructor\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Dataset statistics: {'num_datapoints': 49, 'num_triplets': {'P': 165, 'T': 150}, 'num_unique_entities': {'P': 187, 'T': 169}, 'num_unique_relations': {'P': 72, 'T': 55}}\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Got 49 datapoints from the `data` passed to the constructor\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Dataset statistics: {'num_datapoints': 49, 'num_triplets': {'P': 173, 'T': 150}, 'num_unique_entities': {'P': 192, 'T': 169}, 'num_unique_relations': {'P': 72, 'T': 55}}\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Got 49 datapoints from the `data` passed to the constructor\n",
      "INFO:src.datamodules.ie_generic:[Output DS] Dataset statistics: {'num_datapoints': 49, 'num_triplets': {'P': 127, 'T': 150}, 'num_unique_entities': {'P': 140, 'T': 169}, 'num_unique_relations': {'P': 34, 'T': 55}}\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for target_col, prediction_col in target_col_prediction_col_pairs:\n",
    "    curr_scores = {}\n",
    "    \n",
    "    output_dataset = get_output_dataset(df_merged, target_col, prediction_col)\n",
    "\n",
    "    curr_scores = compute_metrics(output_dataset, scores=curr_scores, bootstrap_n=bootstrap_n)\n",
    "    curr_scores = compute_metrics(output_dataset, macro=True, scores=curr_scores, bootstrap_n=bootstrap_n)\n",
    "    \n",
    "    scores[(target_col, prediction_col)] = curr_scores\n",
    "\n",
    "# pprint(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Micro ~~~\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}</th>\n",
       "      <td>44.96 {\\scriptsize± 10.62}</td>\n",
       "      <td>38.88 {\\scriptsize± 8.66}</td>\n",
       "      <td>43.09 {\\scriptsize± 8.02}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}</th>\n",
       "      <td>35.35 {\\scriptsize± 10.26}</td>\n",
       "      <td>43.53 {\\scriptsize± 9.08}</td>\n",
       "      <td>40.13 {\\scriptsize± 8.62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}</th>\n",
       "      <td>41.58 {\\scriptsize± 11.08}</td>\n",
       "      <td>48.81 {\\scriptsize± 8.60}</td>\n",
       "      <td>46.35 {\\scriptsize± 8.44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} REBEL{\\footnotesize~{Gold}}</th>\n",
       "      <td>69.88 {\\scriptsize± 8.66}</td>\n",
       "      <td>57.50 {\\scriptsize± 8.00}</td>\n",
       "      <td>64.47 {\\scriptsize± 6.89}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         P  \\\n",
       "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}     44.96 {\\scriptsize± 10.62}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}   35.35 {\\scriptsize± 10.26}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}  41.58 {\\scriptsize± 11.08}   \n",
       "\\hspace{4mm} REBEL{\\footnotesize~{Gold}}         69.88 {\\scriptsize± 8.66}   \n",
       "\n",
       "                                                                        R  \\\n",
       "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}     38.88 {\\scriptsize± 8.66}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}   43.53 {\\scriptsize± 9.08}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}  48.81 {\\scriptsize± 8.60}   \n",
       "\\hspace{4mm} REBEL{\\footnotesize~{Gold}}        57.50 {\\scriptsize± 8.00}   \n",
       "\n",
       "                                                                       F1  \n",
       "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}     43.09 {\\scriptsize± 8.02}  \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}   40.13 {\\scriptsize± 8.62}  \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}  46.35 {\\scriptsize± 8.44}  \n",
       "\\hspace{4mm} REBEL{\\footnotesize~{Gold}}        64.47 {\\scriptsize± 6.89}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      " & P & R & F1 \\\\\n",
      "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}} & 44.96 {\\scriptsize± 10.62} & 38.88 {\\scriptsize± 8.66} & 43.09 {\\scriptsize± 8.02} \\\\\n",
      "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}} & 35.35 {\\scriptsize± 10.26} & 43.53 {\\scriptsize± 9.08} & 40.13 {\\scriptsize± 8.62} \\\\\n",
      "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}} & 41.58 {\\scriptsize± 11.08} & 48.81 {\\scriptsize± 8.60} & 46.35 {\\scriptsize± 8.44} \\\\\n",
      "\\hspace{4mm} REBEL{\\footnotesize~{Gold}} & 69.88 {\\scriptsize± 8.66} & 57.50 {\\scriptsize± 8.00} & 64.47 {\\scriptsize± 6.89} \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "~~~ Macro ~~~\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}</th>\n",
       "      <td>29.43 {\\scriptsize± 8.40}</td>\n",
       "      <td>28.57 {\\scriptsize± 7.69}</td>\n",
       "      <td>26.74 {\\scriptsize± 7.85}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}</th>\n",
       "      <td>33.52 {\\scriptsize± 7.25}</td>\n",
       "      <td>35.70 {\\scriptsize± 7.28}</td>\n",
       "      <td>32.88 {\\scriptsize± 6.82}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}</th>\n",
       "      <td>40.80 {\\scriptsize± 7.37}</td>\n",
       "      <td>40.79 {\\scriptsize± 6.95}</td>\n",
       "      <td>39.19 {\\scriptsize± 6.78}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{4mm} REBEL{\\footnotesize~{Gold}}</th>\n",
       "      <td>45.52 {\\scriptsize± 7.97}</td>\n",
       "      <td>44.40 {\\scriptsize± 7.70}</td>\n",
       "      <td>43.55 {\\scriptsize± 7.75}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        P  \\\n",
       "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}     29.43 {\\scriptsize± 8.40}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}   33.52 {\\scriptsize± 7.25}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}  40.80 {\\scriptsize± 7.37}   \n",
       "\\hspace{4mm} REBEL{\\footnotesize~{Gold}}        45.52 {\\scriptsize± 7.97}   \n",
       "\n",
       "                                                                        R  \\\n",
       "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}     28.57 {\\scriptsize± 7.69}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}   35.70 {\\scriptsize± 7.28}   \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}  40.79 {\\scriptsize± 6.95}   \n",
       "\\hspace{4mm} REBEL{\\footnotesize~{Gold}}        44.40 {\\scriptsize± 7.70}   \n",
       "\n",
       "                                                                       F1  \n",
       "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}}     26.74 {\\scriptsize± 7.85}  \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}}   32.88 {\\scriptsize± 6.82}  \n",
       "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}}  39.19 {\\scriptsize± 6.78}  \n",
       "\\hspace{4mm} REBEL{\\footnotesize~{Gold}}        43.55 {\\scriptsize± 7.75}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      " & P & R & F1 \\\\\n",
      "\\hspace{4mm} GenIE{\\footnotesize~{T5-base}} & 29.43 {\\scriptsize± 8.40} & 28.57 {\\scriptsize± 7.69} & 26.74 {\\scriptsize± 7.85} \\\\\n",
      "\\hspace{4mm} SynthIE{\\footnotesize~{T5-base}} & 33.52 {\\scriptsize± 7.25} & 35.70 {\\scriptsize± 7.28} & 32.88 {\\scriptsize± 6.82} \\\\\n",
      "\\hspace{4mm} SynthIE{\\footnotesize~{T5-large}} & 40.80 {\\scriptsize± 7.37} & 40.79 {\\scriptsize± 6.95} & 39.19 {\\scriptsize± 6.78} \\\\\n",
      "\\hspace{4mm} REBEL{\\footnotesize~{Gold}} & 45.52 {\\scriptsize± 7.97} & 44.40 {\\scriptsize± 7.70} & 43.55 {\\scriptsize± 7.75} \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _process_scores(scores):\n",
    "    processed_scores = []\n",
    "\n",
    "    for s in scores:\n",
    "        if isinstance(s, float):\n",
    "            processed_scores.append(f\"{s*100:.2f}\")\n",
    "        else:\n",
    "            error = (s[1] - s[0] + s[2] - s[1]) / 2\n",
    "            processed_scores.append(f\"{s[0]*100:.2f} {{\\\\scriptsize± {error*100:.2f}}}\")\n",
    "\n",
    "    return processed_scores\n",
    "\n",
    "def get_latex_table(model_name2col, ground_truth_cols, macro):\n",
    "    gt_cols = []\n",
    "    model_names = []\n",
    "    precs = []\n",
    "    recs = []\n",
    "    f1s = []\n",
    "\n",
    "    for gt_col in ground_truth_cols:\n",
    "        for model_name in model_name2col:\n",
    "            model_names.append(model_name)\n",
    "            gt_cols.append(gt_col)\n",
    "            precs.append(scores[(gt_col, model_name2col[model_name])][get_metric_name_from_metric(TSPrecision, macro)])\n",
    "            recs.append(scores[(gt_col, model_name2col[model_name])][get_metric_name_from_metric(TSRecall, macro)])\n",
    "            f1s.append(scores[(gt_col, model_name2col[model_name])][get_metric_name_from_metric(TSF1, macro)])\n",
    "\n",
    "    precs = _process_scores(precs)\n",
    "    recs = _process_scores(recs)\n",
    "    f1s = _process_scores(f1s)\n",
    "\n",
    "    df = pd.DataFrame({\"gt_col\": gt_cols, \"model_name\": model_names, \"P\": precs, \"R\": recs, \"F1\": f1s})\n",
    "\n",
    "    df = df.set_index([\"gt_col\", \"model_name\"])\n",
    "    df = df[ORDERED_METRICS]\n",
    "\n",
    "    if len(ground_truth_cols) == 1:\n",
    "        df.index = df.index.droplevel([0])\n",
    "        df.index = [f\"\\\\hspace{{4mm}} {x}\" for x in df.index]\n",
    "\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "print(\"~~~ Micro ~~~\")\n",
    "micro_df = get_latex_table(model_name2col, ground_truth_cols_to_present, macro=False)\n",
    "print(micro_df.style.to_latex())\n",
    "print(\"~~~ Macro ~~~\")\n",
    "macro_df = get_latex_table(model_name2col, ground_truth_cols_to_present, macro=True)\n",
    "print(macro_df.style.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "61a29ff56f295d5304320f1d8bf976f57364ea8d91ff2512104112c4617b5d63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
